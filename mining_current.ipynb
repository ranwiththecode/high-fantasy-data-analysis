{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNmGFcz6XCyOZ1d0C4dIeK0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ranwiththecode/high-fantasy-data-analysis/blob/main/mining_current.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "4WM02MS5zDPO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aec530f6-c40d-435d-a17e-aca2b3f36840"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (2.32.3)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (4.67.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests) (2025.6.15)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "üöÄ Starting review collection...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Collecting reviews:   2%|‚ñè         | 1/58 [00:00<00:26,  2.17page/s, reviews=30, last_page=30]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Total reviews to fetch: ~1738\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Collecting reviews: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 58/58 [01:45<00:00,  1.81s/page, reviews=1738, last_page=28]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üìä Success! Collected 1738 reviews.\n",
            "Saved as:\n",
            "/content/drive/MyDrive/Goodreads_Data/tricksters_choice_reviews.csv\n",
            "/content/drive/MyDrive/Goodreads_Data/tricksters_choice_reviews.json\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# Install required packages\n",
        "!pip install requests pandas tqdm\n",
        "\n",
        "import requests\n",
        "import json\n",
        "import time\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "from google.colab import drive\n",
        "\n",
        "BOOK_TITLE = \"tricksters_choice\"  # Replace with your book's title\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "def get_all_reviews(api_url, initial_payload, headers):\n",
        "    all_reviews = []\n",
        "    page_count = 0\n",
        "    total_reviews = None\n",
        "\n",
        "    # Initialize progress bar\n",
        "    with tqdm(desc=\"Collecting reviews\", unit=\"page\") as pbar:\n",
        "        while True:\n",
        "            try:\n",
        "                response = requests.post(api_url, headers=headers, json=initial_payload, timeout=15)\n",
        "                data = response.json()\n",
        "\n",
        "                # Skip if error in response\n",
        "                if 'errors' in data:\n",
        "                    print(f\"\\nSkipping page due to error: {data['errors']}\")\n",
        "                    break\n",
        "\n",
        "                # Get total count on first page\n",
        "                if total_reviews is None:\n",
        "                    total_reviews = data.get('data', {}).get('getReviews', {}).get('totalCount', 0)\n",
        "                    pbar.total = (total_reviews // initial_payload['variables']['pagination']['limit']) + 1\n",
        "                    print(f\"\\nTotal reviews to fetch: ~{total_reviews}\")\n",
        "\n",
        "                reviews = data.get('data', {}).get('getReviews', {}).get('edges', [])\n",
        "                reviews_collected = len(reviews)\n",
        "\n",
        "                # Process reviews\n",
        "                for review in reviews:\n",
        "                    try:\n",
        "                        all_reviews.append({\n",
        "                            'rating': review['node']['rating'],\n",
        "                            'text': review['node']['text']\n",
        "                        })\n",
        "                    except KeyError as e:\n",
        "                        print(f\"\\nSkipping malformed review: {e}\")\n",
        "                        continue\n",
        "\n",
        "                # Update progress bar\n",
        "                pbar.update(1)\n",
        "                pbar.set_postfix({\n",
        "                    'reviews': len(all_reviews),\n",
        "                    'last_page': reviews_collected\n",
        "                })\n",
        "\n",
        "                # Pagination logic\n",
        "                page_info = data['data']['getReviews']['pageInfo']\n",
        "                if not page_info.get('nextPageToken'):\n",
        "                    break\n",
        "\n",
        "                initial_payload['variables']['pagination']['after'] = page_info['nextPageToken']\n",
        "                page_count += 1\n",
        "                time.sleep(1.5)  # Be gentle with the API\n",
        "\n",
        "            except requests.exceptions.RequestException as e:\n",
        "                print(f\"\\nRequest failed: {e}. Retrying...\")\n",
        "                time.sleep(5)\n",
        "                continue\n",
        "            except json.JSONDecodeError as e:\n",
        "                print(f\"\\nFailed to decode JSON: {e}. Retrying...\")\n",
        "                time.sleep(5)\n",
        "                continue\n",
        "            except Exception as e:\n",
        "                print(f\"\\nUnexpected error: {e}. Retrying...\")\n",
        "                time.sleep(5)\n",
        "                continue\n",
        "\n",
        "    return all_reviews\n",
        "\n",
        "# Configuration\n",
        "config = {\n",
        "    \"api_url\": \"https://kxbwmqov6jgg3daaamb744ycu4.appsync-api.us-east-1.amazonaws.com/graphql\",\n",
        "    \"headers\": {\n",
        "        \"Content-Type\": \"application/json\",\n",
        "        \"X-Api-Key\": \"da2-xpgsdydkbregjhpr6ejzqdhuwy\"\n",
        "    },\n",
        "    \"payload_template\": {\n",
        "        \"operationName\": \"getReviews\",\n",
        "        \"query\": \"\"\"query getReviews($filters: BookReviewsFilterInput!, $pagination: PaginationInput) {\n",
        "            getReviews(filters: $filters, pagination: $pagination) {\n",
        "                totalCount\n",
        "                edges {\n",
        "                    node {\n",
        "                        text\n",
        "                        rating\n",
        "                    }\n",
        "                }\n",
        "                pageInfo { nextPageToken }\n",
        "            }\n",
        "        }\"\"\",\n",
        "        \"variables\": {\n",
        "            \"filters\": {\n",
        "                \"resourceType\": \"WORK\",\n",
        "                \"resourceId\": \"\" # Enter resource ID\n",
        "            },\n",
        "            \"pagination\": {\"limit\": 30}\n",
        "        }\n",
        "    }\n",
        "}\n",
        "\n",
        "# Run the scraper\n",
        "print(\"üöÄ Starting review collection...\")\n",
        "reviews = get_all_reviews(\n",
        "    config[\"api_url\"],\n",
        "    config[\"payload_template\"],\n",
        "    config[\"headers\"]\n",
        ")\n",
        "\n",
        "# Process and save results\n",
        "if reviews:\n",
        "    print(f\"\\nüìä Success! Collected {len(reviews)} reviews.\")\n",
        "\n",
        "    # Create DataFrame directly from the collected reviews\n",
        "    df = pd.DataFrame(reviews)\n",
        "\n",
        "    # Save to Drive\n",
        "    save_path = '/content/drive/MyDrive/Goodreads_Data/'\n",
        "    !mkdir -p \"{save_path}\"\n",
        "\n",
        "    # Clean the title (replace spaces with underscores)\n",
        "    clean_title = BOOK_TITLE.replace(\" \", \"_\")\n",
        "\n",
        "    df.to_csv(f'{save_path}{clean_title}_reviews.csv', index=False)\n",
        "    df.to_json(f'{save_path}{clean_title}_reviews.json', indent=2)\n",
        "\n",
        "    print(f\"Saved as:\\n{save_path}{clean_title}_reviews.csv\\n{save_path}{clean_title}_reviews.json\")\n",
        "else:\n",
        "    print(\"\\n‚ùå No reviews were collected. Check the resource ID and API connection.\")"
      ]
    }
  ]
}