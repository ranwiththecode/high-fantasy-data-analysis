{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMIxthr8ASpYmv6BWa2Q62W",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ranwiththecode/high-fantasy-data-analysis/blob/main/mining_current.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4WM02MS5zDPO"
      },
      "outputs": [],
      "source": [
        "# Install required packages\n",
        "!pip install requests pandas tqdm\n",
        "\n",
        "import requests\n",
        "import json\n",
        "import time\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "from google.colab import drive\n",
        "\n",
        "BOOK_TITLE = \"eragon_paolini\"  # Replace with your book's title\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "def get_all_reviews(api_url, initial_payload, headers):\n",
        "    all_reviews = []\n",
        "    page_count = 0\n",
        "\n",
        "    while True:\n",
        "        try:\n",
        "            response = requests.post(api_url, headers=headers, json=initial_payload, timeout=15)\n",
        "            data = response.json()\n",
        "\n",
        "            # Skip if error in response\n",
        "            if 'errors' in data:\n",
        "                print(f\"Skipping page due to error: {data['errors']}\")\n",
        "                break\n",
        "\n",
        "            reviews = data.get('data', {}).get('getReviews', {}).get('edges', [])\n",
        "\n",
        "            # Process reviews with error handling\n",
        "            for review in reviews:\n",
        "                try:\n",
        "                    # Handle missing creator data\n",
        "                    creator = review['node']['creator'] or {\n",
        "                        'name': 'Anonymous',\n",
        "                        'imageUrlSquare': None\n",
        "                    }\n",
        "\n",
        "                    all_reviews.append({\n",
        "                        **review['node'],\n",
        "                        'creator': creator\n",
        "                    })\n",
        "                except KeyError as e:\n",
        "                    print(f\"Skipping malformed review: {e}\")\n",
        "                    continue\n",
        "\n",
        "            # Pagination logic\n",
        "            page_info = data['data']['getReviews']['pageInfo']\n",
        "            if not page_info.get('nextPageToken'):\n",
        "                break\n",
        "\n",
        "            initial_payload['variables']['pagination']['after'] = page_info['nextPageToken']\n",
        "            page_count += 1\n",
        "            time.sleep(1.5)\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error: {e}. Retrying...\")\n",
        "            time.sleep(5)\n",
        "            continue\n",
        "\n",
        "    return all_reviews\n",
        "\n",
        "# Configuration\n",
        "config = {\n",
        "    \"api_url\": \"https://kxbwmqov6jgg3daaamb744ycu4.appsync-api.us-east-1.amazonaws.com/graphql\",\n",
        "    \"headers\": {\n",
        "        \"Content-Type\": \"application/json\",\n",
        "        \"X-Api-Key\": \"da2-xpgsdydkbregjhpr6ejzqdhuwy\"\n",
        "    },\n",
        "    \"payload_template\": {\n",
        "        \"operationName\": \"getReviews\",\n",
        "        \"query\": \"\"\"query getReviews($filters: BookReviewsFilterInput!, $pagination: PaginationInput) {\n",
        "            getReviews(filters: $filters, pagination: $pagination) {\n",
        "                totalCount\n",
        "                edges {\n",
        "                    node {\n",
        "                        id\n",
        "                        creator { name imageUrlSquare }\n",
        "                        text\n",
        "                        rating\n",
        "                        createdAt\n",
        "                        updatedAt\n",
        "                    }\n",
        "                }\n",
        "                pageInfo { nextPageToken }\n",
        "            }\n",
        "        }\"\"\",\n",
        "        \"variables\": {\n",
        "            \"filters\": {\n",
        "                \"resourceType\": \"WORK\",\n",
        "                \"resourceId\": \"\" # Enter resource ID\n",
        "            },\n",
        "            \"pagination\": {\"limit\": 30}\n",
        "        }\n",
        "    }\n",
        "}\n",
        "\n",
        "# Run the scraper\n",
        "print(\"ðŸš€ Starting review collection...\")\n",
        "reviews = get_all_reviews(\n",
        "    config[\"api_url\"],\n",
        "    config[\"payload_template\"],\n",
        "    config[\"headers\"]\n",
        ")\n",
        "\n",
        "# Process and save results\n",
        "if reviews:\n",
        "    print(f\"\\nðŸ“Š Success! Collected {len(reviews)} reviews.\")\n",
        "\n",
        "    df = pd.json_normalize([{\n",
        "        **r['node'],\n",
        "        'creator_name': r['node']['creator']['name'],\n",
        "        'creator_image': r['node']['creator']['imageUrlSquare']\n",
        "    } for r in reviews])\n",
        "\n",
        "    # Save to Drive\n",
        "    # Replace your save code with this:\n",
        "save_path = '/content/drive/MyDrive/Goodreads_Data/'\n",
        "!mkdir -p \"{save_path}\"\n",
        "\n",
        "# Clean the title (replace spaces with underscores)\n",
        "clean_title = BOOK_TITLE.replace(\" \", \"_\")\n",
        "\n",
        "df.to_csv(f'{save_path}{clean_title}_reviews.csv', index=False)\n",
        "df.to_json(f'{save_path}{clean_title}_reviews.json', indent=2)\n",
        "\n",
        "print(f\"Saved as:\\n{save_path}{clean_title}_reviews.csv\\n{save_path}{clean_title}_reviews.json\")\n"
      ]
    }
  ]
}